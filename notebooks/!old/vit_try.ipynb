{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a5b6b8e",
   "metadata": {},
   "source": [
    "# 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67c0b21b-046b-48f3-8183-9f7941a16857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.8/site-packages (2.4.0)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Collecting flatbuffers>=23.1.21 (from tensorflow)\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.32.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow)\n",
      "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow)\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow)\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.59.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.35.0)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow)\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.14,>=2.13->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.14,>=2.13->tensorflow)\n",
      "  Downloading google_auth-2.23.4-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (6.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
      "Downloading tensorflow-2.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m479.6/479.6 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.59.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m105.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.34.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.23.4-py2.py3-none-any.whl (183 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.3/183.3 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Installing collected packages: libclang, flatbuffers, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, keras, grpcio, absl-py, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 1.12\n",
      "    Uninstalling flatbuffers-1.12:\n",
      "      Successfully uninstalled flatbuffers-1.12\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.4.0\n",
      "    Uninstalling tensorflow-estimator-2.4.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.32.0\n",
      "    Uninstalling grpcio-1.32.0:\n",
      "      Successfully uninstalled grpcio-1.32.0\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 0.15.0\n",
      "    Uninstalling absl-py-0.15.0:\n",
      "      Successfully uninstalled absl-py-0.15.0\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 1.35.0\n",
      "    Uninstalling google-auth-1.35.0:\n",
      "      Successfully uninstalled google-auth-1.35.0\n",
      "  Attempting uninstall: google-auth-oauthlib\n",
      "    Found existing installation: google-auth-oauthlib 0.4.6\n",
      "    Uninstalling google-auth-oauthlib-0.4.6:\n",
      "      Successfully uninstalled google-auth-oauthlib-0.4.6\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.4.0\n",
      "    Uninstalling tensorboard-2.4.0:\n",
      "      Successfully uninstalled tensorboard-2.4.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.4.0\n",
      "    Uninstalling tensorflow-2.4.0:\n",
      "      Successfully uninstalled tensorflow-2.4.0\n",
      "Successfully installed absl-py-2.0.0 flatbuffers-23.5.26 google-auth-2.23.4 google-auth-oauthlib-1.0.0 grpcio-1.59.2 keras-2.13.1 libclang-16.0.6 tensorboard-2.13.0 tensorboard-data-server-0.7.2 tensorflow-2.13.1 tensorflow-estimator-2.13.0 tensorflow-io-gcs-filesystem-0.34.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade tensorflow\n",
    "# !pip install ipynb_path\n",
    "# !pip install --upgrade tensorflow\n",
    "# !pip install typing-extensions==4.1.1\n",
    "# !pip install numba==0.49\n",
    "# !pip install numpy==1.24.3\n",
    "# !pip install numba==0.56.2\n",
    "# !pip install comm==0.1.3\n",
    "# !pip install cupy-cuda11x\n",
    "# !pip install git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656acfde",
   "metadata": {},
   "source": [
    "## Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ad679ac-441d-41ce-9e20-af8d2c814334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\n",
      "  Downloading timm-0.9.10-py3-none-any.whl.metadata (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.8/59.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.8/site-packages (from timm) (2.1.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.8/site-packages (from timm) (0.12.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from timm) (6.0)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.8/site-packages (from timm) (0.17.3)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.8/site-packages (from timm) (0.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from torch>=1.7->timm) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.7->timm) (4.1.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.8/site-packages (from torch>=1.7->timm) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.8/site-packages (from torch>=1.7->timm) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from torch>=1.7->timm) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.8/site-packages (from torch>=1.7->timm) (2023.9.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch>=1.7->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch>=1.7->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch>=1.7->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.8/site-packages (from torch>=1.7->timm) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.8/site-packages (from torch>=1.7->timm) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.8/site-packages (from torch>=1.7->timm) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.8/site-packages (from torch>=1.7->timm) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.8/site-packages (from torch>=1.7->timm) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.8/site-packages (from torch>=1.7->timm) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.8/site-packages (from torch>=1.7->timm) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch>=1.7->timm) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.8/site-packages (from torch>=1.7->timm) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7->timm) (12.3.52)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from huggingface-hub->timm) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub->timm) (4.65.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub->timm) (23.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from torchvision->timm) (1.23.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.8/site-packages (from torchvision->timm) (10.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->torch>=1.7->timm) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface-hub->timm) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface-hub->timm) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface-hub->timm) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface-hub->timm) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.8/site-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
      "Downloading timm-0.9.10-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: timm\n",
      "Successfully installed timm-0.9.10\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53e60f59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import gc  \n",
    "from albumentations import (\n",
    "    Compose, Normalize, Resize,\n",
    "    RandomResizedCrop, HorizontalFlip,\n",
    "    RandomBrightnessContrast, ShiftScaleRotate\n",
    ")\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from tqdm import tqdm\n",
    "import ipynb_path\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c751cc68-818b-4600-aa3a-54fae3eb42c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "from PIL import Image\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de489ddb-ed45-435f-b6ad-bbad443c0458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vit_try\n"
     ]
    }
   ],
   "source": [
    "# ノートブック名を取得\n",
    "__file__ = ipynb_path.get()\n",
    "notebook_name = __file__.split('/')[-1].split('.')[0]\n",
    "\n",
    "print(notebook_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99bbf73d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    patience=20\n",
    "    num_epochs=20\n",
    "    mixup_epochs=0\n",
    "    batch_size=24\n",
    "    \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd592c6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "# Use a chosen seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1fc9498",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available and set PyTorch to use GPU or CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce585db4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20231113074053\n"
     ]
    }
   ],
   "source": [
    "# Get current date and time in JST\n",
    "jst = pytz.timezone('Asia/Tokyo')\n",
    "current_datetime = datetime.now(jst)\n",
    "# Get current date and time\n",
    "formatted_datetime = current_datetime.strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "print(formatted_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71301958",
   "metadata": {},
   "source": [
    "## Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d474b9",
   "metadata": {},
   "source": [
    "## def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29b83035",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def view_img(dir_name, file_name):\n",
    "    \n",
    "    info_table = pd.read_csv(f'../data/{dir_name}.csv', header=None, names=['name', 'label'])\n",
    "    target_label = info_table[info_table['name']==f'{file_name}']['label']\n",
    "    \n",
    "    # # Display the image\n",
    "    img = Image.open(f'../data/{dir_name}/'+file_name)\n",
    "    # img = Image.open('../data/train_1/'+f'train_1811.png')\n",
    "    \n",
    "    plt.title(file_name)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Label:\", target_label.values[0])  # values[0] is used to get the first value if multiple rows match the condition\n",
    "    print(\"Size of the image:\", img.size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd918cf",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "376029bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../data/train_1.csv', header=None, names=['name', 'label'])\n",
    "# df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4337c399",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# random_idx = random.choice(range(len(df)))\n",
    "# file_name = f'train_{random_idx}.png'\n",
    "# dir_name = 'train_1'\n",
    "\n",
    "# view_img(dir_name, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "705e13c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Directory to search\n",
    "# directory = \"../data/train_1/\"\n",
    "\n",
    "# # Maximum file size in bytes (40K in this case)\n",
    "# max_size = 40 * 1024\n",
    "\n",
    "# # Get list of files in the directory and subdirectories\n",
    "# file_list = []\n",
    "\n",
    "# for directory in [\"../data/train_1/\",\"../data/train_2/\",\"../data/train_3/\",\"../data/train_4/\"]:\n",
    "#     for foldername, subfolders, filenames in os.walk(directory):\n",
    "#         for filename in filenames:\n",
    "#             full_path = os.path.join(foldername, filename)\n",
    "#             if os.path.getsize(full_path) <= max_size:\n",
    "#                 file_list.append(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5df6ad25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e08d688",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# file_name = f'train_1474.png'\n",
    "# dir_name = 'train_3'\n",
    "\n",
    "# view_img(dir_name, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a407131",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Get image paths for label 0 and 1\n",
    "# image_paths_0 = df[df['label'] == 0]['name'].values\n",
    "# image_paths_1 = df[df['label'] == 1]['name'].values\n",
    "\n",
    "# # Function to display images\n",
    "# def display_images(image_paths, title):\n",
    "#     plt.figure(figsize=(10,10))\n",
    "#     for i in range(9):  # display 9 images\n",
    "#         plt.subplot(3,3,i+1)\n",
    "#         img = Image.open(image_paths[i])\n",
    "#         plt.imshow(img)\n",
    "#         plt.title(title)\n",
    "#         plt.axis('off')\n",
    "#     plt.show()\n",
    "\n",
    "# # Display images for label 0 and 1\n",
    "# display_images('../data/train_1/'+ image_paths_0, 'label_0')\n",
    "# display_images('../data/train_1/'+ image_paths_1, 'label_1')\n",
    "\n",
    "# ## 画像が欠損しているデータもあり"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d422cefc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df.groupby('label')['name'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781e1668",
   "metadata": {},
   "source": [
    "# ベースモデル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0606e",
   "metadata": {},
   "source": [
    "## 学習フェーズ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0add230",
   "metadata": {},
   "source": [
    "### 関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63d2afa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_transforms():\n",
    "    transforms_dict = {\n",
    "        'train': Compose([\n",
    "            RandomResizedCrop(224, 224),\n",
    "            HorizontalFlip(),\n",
    "            RandomBrightnessContrast(),\n",
    "            ShiftScaleRotate(),\n",
    "            Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ]),\n",
    "        'valid': Compose([\n",
    "            Resize(224, 224),\n",
    "            Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ]),\n",
    "    }\n",
    "    return transforms_dict\n",
    "\n",
    "\n",
    "def load_datasets(df, root_dir, transforms_dict):\n",
    "    train_df, valid_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    datasets = {\n",
    "        'train': CustomImageDataset(train_df, root_dir, transform=transforms_dict['train']),\n",
    "        'valid': CustomImageDataset(valid_df, root_dir, transform=transforms_dict['valid'])\n",
    "    }\n",
    "    return datasets\n",
    "\n",
    "\n",
    "def get_dataloaders(datasets, batch_size):\n",
    "    dataloaders = {\n",
    "        'train': DataLoader(datasets['train'], batch_size=batch_size, shuffle=True),\n",
    "        'valid': DataLoader(datasets['valid'], batch_size=batch_size, shuffle=False)\n",
    "    }\n",
    "    return dataloaders\n",
    "\n",
    "    \n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, df, root_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.df.iloc[idx, 0])\n",
    "        image = cv2.imread(img_path)  # Use OpenCV to read the image\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB\n",
    "        label = self.df.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image)  # Apply the transformations\n",
    "            image = transformed[\"image\"]\n",
    "        return image, label\n",
    "    \n",
    "def mixup_data(x, y, alpha=0.4):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "          \n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "        \n",
    "    # val_loss_minの値を取得\n",
    "    def get_value(self):\n",
    "        return self.val_loss_min\n",
    "        \n",
    "def train_model_mixup_el_stop(dataloaders, model, criterion, optimizer, num_epochs, file_name, mixup_epochs, patience):\n",
    "    early_stopping = EarlyStopping(patience=patience, path=f'../models/{formatted_datetime}_{file_name}.pth',verbose=True)\n",
    "    stop_training = False  # 早期停止フラグ\n",
    "\n",
    "    logs = []\n",
    "    train_loss = []\n",
    "    train_auc = []\n",
    "    val_loss = []\n",
    "    val_auc = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            correct_predictions = 0\n",
    "            for inputs, labels in tqdm(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Mixupを適用する条件\n",
    "                    # if phase == 'train' and epoch < mixup_epochs:\n",
    "                    #     inputs, labels_a, labels_b, lmd = mixup_data(inputs, labels)\n",
    "                    #     outputs = model(inputs)\n",
    "                    #     loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lmd)\n",
    "                    #     _, preds = torch.max(outputs, 1)\n",
    "                    #     # Mixupでの正確さの計算\n",
    "                    #     correct_predictions += lmd * torch.sum(preds == labels_a).item() + (1.0 - lmd) * torch.sum(preds == labels_b).item()\n",
    "                    # else:\n",
    "                    #     outputs = model(inputs)\n",
    "                    #     _, preds = torch.max(outputs, 1)\n",
    "                    #     loss = criterion(outputs, labels)\n",
    "                    #     # 通常の正確さの計算\n",
    "                    #     correct_predictions += torch.sum(preds == labels.data).item()\n",
    "                    \n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    # 通常の正確さの計算\n",
    "                    correct_predictions += torch.sum(preds == labels.data).item()\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = correct_predictions / len(dataloaders[phase].dataset)\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            if phase == 'train':\n",
    "                train_loss.append(epoch_loss)\n",
    "                train_auc.append(epoch_acc)\n",
    "            \n",
    "            if phase == 'valid':\n",
    "                val_loss.append(epoch_loss)\n",
    "                val_auc.append(epoch_acc)\n",
    "            \n",
    "            if phase == 'valid':\n",
    "                early_stopping(-epoch_acc, model)\n",
    "                if early_stopping.early_stop:\n",
    "                    print(\"Early stopping\")\n",
    "                    stop_training = True\n",
    "                    break\n",
    "\n",
    "        if stop_training:\n",
    "            break\n",
    "    \n",
    "    # ログを保存\n",
    "    df = pd.DataFrame({'train_loss':train_loss,\n",
    "                      'train_auc':train_auc,\n",
    "                       'val_loss':val_loss,\n",
    "                       'val_auc':val_auc})\n",
    "    df.to_csv(f\"log_output_{notebook_name}_{file_name}.csv\")\n",
    " \n",
    "    print('Finished Training') \n",
    "    \n",
    "    return early_stopping.get_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2a4fdb",
   "metadata": {},
   "source": [
    "### 実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f31e5cbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== train_4  学習中 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c870182e4a43e0a4ece73cad702e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/113M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 166/166 [01:36<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6110 Acc: 0.6610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 42/42 [00:15<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.5202 Acc: 0.7205\n",
      "Validation loss decreased (inf --> -0.720484).  Saving model ...\n",
      "Epoch 2/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 166/166 [01:30<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5032 Acc: 0.7585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 42/42 [00:14<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.4766 Acc: 0.7911\n",
      "Validation loss decreased (-0.720484 --> -0.791120).  Saving model ...\n",
      "Epoch 3/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 166/166 [01:30<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4452 Acc: 0.7933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 42/42 [00:14<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.8188 Acc: 0.6519\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 4/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 166/166 [01:30<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3954 Acc: 0.8251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 42/42 [00:14<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.2727 Acc: 0.8759\n",
      "Validation loss decreased (-0.791120 --> -0.875883).  Saving model ...\n",
      "Epoch 5/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 166/166 [01:30<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3330 Acc: 0.8576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 42/42 [00:14<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.3130 Acc: 0.8678\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 6/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 166/166 [01:30<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3087 Acc: 0.8723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 42/42 [00:14<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.2400 Acc: 0.8951\n",
      "Validation loss decreased (-0.875883 --> -0.895055).  Saving model ...\n",
      "Epoch 7/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 166/166 [01:30<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3003 Acc: 0.8677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 42/42 [00:14<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.1837 Acc: 0.9516\n",
      "Validation loss decreased (-0.895055 --> -0.951564).  Saving model ...\n",
      "Epoch 8/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 166/166 [01:30<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2339 Acc: 0.9043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 42/42 [00:14<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.2818 Acc: 0.8729\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 9/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 166/166 [01:30<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2111 Acc: 0.9137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 42/42 [00:14<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.2217 Acc: 0.9092\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 10/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 166/166 [01:30<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1837 Acc: 0.9316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 42/42 [00:14<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.3275 Acc: 0.8759\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 11/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 166/166 [01:30<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2072 Acc: 0.9197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 42/42 [00:14<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.1550 Acc: 0.9324\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 12/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 166/166 [01:30<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1769 Acc: 0.9329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 42/42 [00:14<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.1241 Acc: 0.9536\n",
      "Validation loss decreased (-0.951564 --> -0.953582).  Saving model ...\n",
      "Epoch 13/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 166/166 [01:30<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1475 Acc: 0.9425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 42/42 [00:14<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.1110 Acc: 0.9657\n",
      "Validation loss decreased (-0.953582 --> -0.965691).  Saving model ...\n",
      "Epoch 14/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 166/166 [01:30<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1532 Acc: 0.9404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 42/42 [00:14<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.2721 Acc: 0.8971\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 15/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 166/166 [01:30<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1975 Acc: 0.9180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 42/42 [00:14<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.2105 Acc: 0.9213\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 16/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 166/166 [01:30<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1436 Acc: 0.9422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 42/42 [00:14<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.1014 Acc: 0.9596\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 17/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 166/166 [01:30<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1242 Acc: 0.9500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 42/42 [00:14<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.1426 Acc: 0.9374\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 18/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 166/166 [01:30<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1235 Acc: 0.9520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 42/42 [00:14<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.1269 Acc: 0.9435\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 19/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 166/166 [01:30<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1096 Acc: 0.9561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 42/42 [00:14<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.0991 Acc: 0.9617\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 20/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 166/166 [01:30<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1017 Acc: 0.9601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 42/42 [00:14<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.0701 Acc: 0.9768\n",
      "Validation loss decreased (-0.965691 --> -0.976791).  Saving model ...\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dict=dict()\n",
    "\n",
    "# for ds in ['train_1','train_2','train_3','train_4']:\n",
    "for ds in ['train_4']:\n",
    "    print(f'=== {ds}  学習中 ===')\n",
    "    \n",
    "    # Load labels from csv\n",
    "    df = pd.read_csv(f'../data/{ds}.csv', header=None, names=['name', 'label'])\n",
    "    \n",
    "    # 40kB以下の空白画像をdfから削除\n",
    "    file_list = []\n",
    "    for foldername, subfolders, filenames in os.walk(os.path.join(\"../data/\",ds)):\n",
    "        for filename in filenames:\n",
    "            full_path = os.path.join(foldername, filename)\n",
    "            max_size = 40 * 1024\n",
    "            if os.path.getsize(full_path) <= max_size:\n",
    "                file_list.append(filename)\n",
    "    df = df[~df['name'].isin(file_list)]\n",
    "    \n",
    "    # Get transforms\n",
    "    transforms_dict = get_transforms()\n",
    "\n",
    "    # Load datasets\n",
    "    datasets = load_datasets(df, f'../data/{ds}/', transforms_dict)\n",
    "\n",
    "    # Create dataloaders\n",
    "    dataloaders = get_dataloaders(datasets, batch_size=config.batch_size)\n",
    "\n",
    "    # Define model\n",
    "    # config = SwinConfig.from_pretrained(\"microsoft/swinv2-tiny-patch4-window8-256\", num_labels=2)\n",
    "    # model = Swinv2ForImageClassification.from_pretrained(\"microsoft/swinv2-tiny-patch4-window8-256\", config=config)\n",
    "    \n",
    "    # model = torchvision.models.resnet50(pretrained=True)\n",
    "    # model.fc = nn.Linear(model.head.in_features, 2) \n",
    "    model = timm.create_model('swinv2_cr_tiny_ns_224.sw_in1k', pretrained=True, num_classes=2)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Train the model\n",
    "    eval_dict[ds]= train_model_mixup_el_stop(\n",
    "        dataloaders,\n",
    "        model, \n",
    "        criterion,\n",
    "        optimizer,\n",
    "        num_epochs=config.num_epochs,\n",
    "        file_name=ds, \n",
    "        mixup_epochs=config.mixup_epochs,\n",
    "        patience=config.patience\n",
    "    )\n",
    "\n",
    "del df\n",
    "del dataloaders\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ea2a53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a91d7f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc_ave = sum(eval_dict.values()) / len(eval_dict)\n",
    "acc_ave = round(acc_ave, 4)\n",
    "acc_ave = str(acc_ave)\n",
    "acc_ave = acc_ave.replace('.', '_')\n",
    "\n",
    "print(acc_ave)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddede80",
   "metadata": {},
   "source": [
    "## 予測フェーズ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acdc761",
   "metadata": {},
   "source": [
    "### 関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b34d36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = os.listdir(root_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.image_files[idx])\n",
    "        image = cv2.imread(img_path)  # Use OpenCV to read the image\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image)\n",
    "            image = transformed[\"image\"]\n",
    "        return image, self.image_files[idx] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebb0f43",
   "metadata": {},
   "source": [
    "### 実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebea41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_dict = get_transforms()\n",
    "\n",
    "test_data = TestDataset(root_dir='../data/evaluation/', transform=transforms_dict['valid'])\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "# モデルのパスをリストにします\n",
    "model_paths = [\n",
    "    f'../models/{formatted_datetime}_train_1.pth',\n",
    "    f'../models/{formatted_datetime}_train_2.pth',\n",
    "    f'../models/{formatted_datetime}_train_3.pth',\n",
    "    f'../models/{formatted_datetime}_train_4.pth',\n",
    "] \n",
    "\n",
    "# 空のリストを作成して各モデルの予測を格納します\n",
    "all_predictions = []\n",
    "\n",
    "for model_path in model_paths:\n",
    "    print('■実行中:', model_path)\n",
    "    \n",
    "    # モデルのインスタンスを作成します（ここではResNet34を使用）\n",
    "    model = torchvision.models.resnet50()\n",
    "    model.fc = nn.Linear(model.fc.in_features, 2) \n",
    "\n",
    "    # 状態辞書をロードします\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    # モデルをGPUに移動します\n",
    "    model = model.to(device)\n",
    "\n",
    "    # モデルを評価モードに設定します\n",
    "    model.eval()\n",
    "\n",
    "    # このモデルの予測を格納するリストを作成します\n",
    "    model_predictions = []\n",
    "\n",
    "    # データローダーからバッチを取得して予測を行います\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader):\n",
    "            images, _ = data\n",
    "            images = images.to(device)\n",
    "            \n",
    "            logits = model(images)\n",
    "            probabilities = F.softmax(logits, dim=1)  # apply softmax to convert logits to probabilities\n",
    "            model_predictions.extend(probabilities.tolist())  # convert PyTorch tensor to Python list\n",
    "\n",
    "    # すべてのモデルの予測を格納するリストにこのモデルの予測を追加します\n",
    "    all_predictions.append(model_predictions)\n",
    "\n",
    "# 全モデルの予測を平均します\n",
    "final_predictions = np.mean(all_predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7517aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit用に整形\n",
    "# Create a DataFrame with the image names and the probabilities\n",
    "df_submission = pd.DataFrame({\n",
    "    'image_name': [f'test_{i}.png' for i in range(len(final_predictions))],\n",
    "    'probability': [probs[1] for probs in final_predictions]\n",
    "})\n",
    "\n",
    "# Write the DataFrame to a csv file\n",
    "# df_submission.to_csv(f'../data/submit/submission_{formatted_datetime}_acc{acc_ave}.csv', index=False,header=False)\n",
    "df_submission.to_csv(f'../data/submit/submission_{formatted_datetime}.csv', index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be7a868",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.probability.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcb6f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.probability.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac8955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.probability.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35261963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
