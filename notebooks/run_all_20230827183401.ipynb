{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a5b6b8e",
   "metadata": {},
   "source": [
    "# 準備"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656acfde",
   "metadata": {},
   "source": [
    "## Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53e60f59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import gc  \n",
    "from albumentations import (\n",
    "    Compose, Normalize, Resize,\n",
    "    RandomResizedCrop, HorizontalFlip,\n",
    "    RandomBrightnessContrast, ShiftScaleRotate\n",
    ")\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99bbf73d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    patience=10\n",
    "    num_epochs=80\n",
    "    mixup_epochs=5\n",
    "    batch_size=24\n",
    "    \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd592c6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "# Use a chosen seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1fc9498",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available and set PyTorch to use GPU or CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce585db4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20230924202244\n"
     ]
    }
   ],
   "source": [
    "# Get current date and time in JST\n",
    "jst = pytz.timezone('Asia/Tokyo')\n",
    "current_datetime = datetime.now(jst)\n",
    "# Get current date and time\n",
    "formatted_datetime = current_datetime.strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "print(formatted_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "443113de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# formatted_datetime=20230827183401"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71301958",
   "metadata": {},
   "source": [
    "## Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d474b9",
   "metadata": {},
   "source": [
    "## def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29b83035",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def view_img(dir_name, file_name):\n",
    "    \n",
    "    info_table = pd.read_csv(f'../data/{dir_name}.csv', header=None, names=['name', 'label'])\n",
    "    target_label = info_table[info_table['name']==f'{file_name}']['label']\n",
    "    \n",
    "    # # Display the image\n",
    "    img = Image.open(f'../data/{dir_name}/'+file_name)\n",
    "    # img = Image.open('../data/train_1/'+f'train_1811.png')\n",
    "    \n",
    "    plt.title(file_name)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Label:\", target_label.values[0])  # values[0] is used to get the first value if multiple rows match the condition\n",
    "    print(\"Size of the image:\", img.size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd918cf",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "376029bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../data/train_1.csv', header=None, names=['name', 'label'])\n",
    "# df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4337c399",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# random_idx = random.choice(range(len(df)))\n",
    "# file_name = f'train_{random_idx}.png'\n",
    "# dir_name = 'train_1'\n",
    "\n",
    "# view_img(dir_name, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "705e13c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Directory to search\n",
    "# directory = \"../data/train_1/\"\n",
    "\n",
    "# # Maximum file size in bytes (40K in this case)\n",
    "# max_size = 40 * 1024\n",
    "\n",
    "# # Get list of files in the directory and subdirectories\n",
    "# file_list = []\n",
    "\n",
    "# for directory in [\"../data/train_1/\",\"../data/train_2/\",\"../data/train_3/\",\"../data/train_4/\"]:\n",
    "#     for foldername, subfolders, filenames in os.walk(directory):\n",
    "#         for filename in filenames:\n",
    "#             full_path = os.path.join(foldername, filename)\n",
    "#             if os.path.getsize(full_path) <= max_size:\n",
    "#                 file_list.append(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5df6ad25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e08d688",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# file_name = f'train_1474.png'\n",
    "# dir_name = 'train_3'\n",
    "\n",
    "# view_img(dir_name, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a407131",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Get image paths for label 0 and 1\n",
    "# image_paths_0 = df[df['label'] == 0]['name'].values\n",
    "# image_paths_1 = df[df['label'] == 1]['name'].values\n",
    "\n",
    "# # Function to display images\n",
    "# def display_images(image_paths, title):\n",
    "#     plt.figure(figsize=(10,10))\n",
    "#     for i in range(9):  # display 9 images\n",
    "#         plt.subplot(3,3,i+1)\n",
    "#         img = Image.open(image_paths[i])\n",
    "#         plt.imshow(img)\n",
    "#         plt.title(title)\n",
    "#         plt.axis('off')\n",
    "#     plt.show()\n",
    "\n",
    "# # Display images for label 0 and 1\n",
    "# display_images('../data/train_1/'+ image_paths_0, 'label_0')\n",
    "# display_images('../data/train_1/'+ image_paths_1, 'label_1')\n",
    "\n",
    "# ## 画像が欠損しているデータもあり"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d422cefc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df.groupby('label')['name'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781e1668",
   "metadata": {},
   "source": [
    "# ベースモデル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0606e",
   "metadata": {},
   "source": [
    "## 学習フェーズ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0add230",
   "metadata": {},
   "source": [
    "### 関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63d2afa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_transforms():\n",
    "    transforms_dict = {\n",
    "        'train': Compose([\n",
    "            RandomResizedCrop(512, 512),\n",
    "            HorizontalFlip(),\n",
    "            RandomBrightnessContrast(),\n",
    "            ShiftScaleRotate(),\n",
    "            Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ]),\n",
    "        'valid': Compose([\n",
    "            Resize(512, 512),\n",
    "            Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ]),\n",
    "    }\n",
    "    return transforms_dict\n",
    "\n",
    "\n",
    "def load_datasets(df, root_dir, transforms_dict):\n",
    "    train_df, valid_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    datasets = {\n",
    "        'train': CustomImageDataset(train_df, root_dir, transform=transforms_dict['train']),\n",
    "        'valid': CustomImageDataset(valid_df, root_dir, transform=transforms_dict['valid'])\n",
    "    }\n",
    "    return datasets\n",
    "\n",
    "\n",
    "def get_dataloaders(datasets, batch_size):\n",
    "    dataloaders = {\n",
    "        'train': DataLoader(datasets['train'], batch_size=batch_size, shuffle=True),\n",
    "        'valid': DataLoader(datasets['valid'], batch_size=batch_size, shuffle=False)\n",
    "    }\n",
    "    return dataloaders\n",
    "\n",
    "    \n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, df, root_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.df.iloc[idx, 0])\n",
    "        image = cv2.imread(img_path)  # Use OpenCV to read the image\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB\n",
    "        label = self.df.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image)  # Apply the transformations\n",
    "            image = transformed[\"image\"]\n",
    "        return image, label\n",
    "    \n",
    "def train_model(dataloaders, model, criterion, optimizer, num_epochs, file_name):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            correct_predictions = 0\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                correct_predictions += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = correct_predictions.double() / len(dataloaders[phase].dataset)\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            \n",
    "\n",
    "\n",
    "    torch.save(model.state_dict(), f'../models/{formatted_datetime}_{file_name}.pth')\n",
    "    print('Finished Training')\n",
    "    \n",
    "    \n",
    "def mixup_data(x, y, alpha=0.4):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "def train_model_mixup(dataloaders, model, criterion, optimizer, num_epochs, file_name, mixup_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            correct_predictions = 0\n",
    "            for inputs, labels in tqdm(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Mixupを適用する条件\n",
    "                    if phase == 'train' and epoch < mixup_epochs:\n",
    "                        inputs, labels_a, labels_b, lmd = mixup_data(inputs, labels)\n",
    "                        outputs = model(inputs)\n",
    "                        loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lmd)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        # Mixupでの正確さの計算\n",
    "                        correct_predictions += lmd * torch.sum(preds == labels_a).item() + (1.0 - lmd) * torch.sum(preds == labels_b).item()\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        # 通常の正確さの計算\n",
    "                        correct_predictions += torch.sum(preds == labels.data).item()\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = correct_predictions / len(dataloaders[phase].dataset)\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "    torch.save(model.state_dict(), f'../models/{formatted_datetime}_{file_name}.pth')\n",
    "    print('Finished Training')\n",
    "          \n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "        \n",
    "    # val_loss_minの値を取得\n",
    "    def get_value(self):\n",
    "        return self.val_loss_min\n",
    "        \n",
    "def train_model_mixup_el_stop(dataloaders, model, criterion, optimizer, num_epochs, file_name, mixup_epochs, patience):\n",
    "    early_stopping = EarlyStopping(patience=patience, path=f'../models/{formatted_datetime}_{file_name}.pth',verbose=True)\n",
    "    stop_training = False  # 早期停止フラグ\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            correct_predictions = 0\n",
    "            for inputs, labels in tqdm(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Mixupを適用する条件\n",
    "                    if phase == 'train' and epoch < mixup_epochs:\n",
    "                        inputs, labels_a, labels_b, lmd = mixup_data(inputs, labels)\n",
    "                        outputs = model(inputs)\n",
    "                        loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lmd)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        # Mixupでの正確さの計算\n",
    "                        correct_predictions += lmd * torch.sum(preds == labels_a).item() + (1.0 - lmd) * torch.sum(preds == labels_b).item()\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        # 通常の正確さの計算\n",
    "                        correct_predictions += torch.sum(preds == labels.data).item()\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = correct_predictions / len(dataloaders[phase].dataset)\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            \n",
    "            if phase == 'valid':\n",
    "                early_stopping(-epoch_acc, model)\n",
    "                if early_stopping.early_stop:\n",
    "                    print(\"Early stopping\")\n",
    "                    stop_training = True\n",
    "                    break\n",
    "\n",
    "        if stop_training:\n",
    "            break\n",
    " \n",
    "    print('Finished Training') \n",
    "    \n",
    "    return early_stopping.get_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2a4fdb",
   "metadata": {},
   "source": [
    "### 実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31e5cbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== train_1  学習中 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/jovyan/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████████████████████████████████| 97.8M/97.8M [00:06<00:00, 16.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 165/165 [04:14<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5472 Acc: 0.7172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 42/42 [00:30<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.3218 Acc: 0.8789\n",
      "Validation loss decreased (inf --> -0.878910).  Saving model ...\n",
      "Epoch 2/80\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 165/165 [04:18<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4362 Acc: 0.8107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 42/42 [00:27<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.2861 Acc: 0.8809\n",
      "Validation loss decreased (-0.878910 --> -0.880928).  Saving model ...\n",
      "Epoch 3/80\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████▊                       | 74/165 [01:55<02:22,  1.56s/it]"
     ]
    }
   ],
   "source": [
    "eval_dict=dict()\n",
    "\n",
    "for ds in ['train_1','train_2','train_3','train_4']:\n",
    "\n",
    "    print(f'=== {ds}  学習中 ===')\n",
    "    \n",
    "    # Load labels from csv\n",
    "    df = pd.read_csv(f'../data/{ds}.csv', header=None, names=['name', 'label'])\n",
    "    \n",
    "    # 40kB以下の空白画像をdfから削除\n",
    "    file_list = []\n",
    "    for foldername, subfolders, filenames in os.walk(os.path.join(\"../data/\",ds)):\n",
    "        for filename in filenames:\n",
    "            full_path = os.path.join(foldername, filename)\n",
    "            max_size = 40 * 1024\n",
    "            if os.path.getsize(full_path) <= max_size:\n",
    "                file_list.append(filename)\n",
    "    df = df[~df['name'].isin(file_list)]\n",
    "    \n",
    "    # Get transforms\n",
    "    transforms_dict = get_transforms()\n",
    "\n",
    "    # Load datasets\n",
    "    datasets = load_datasets(df, f'../data/{ds}/', transforms_dict)\n",
    "\n",
    "    # Create dataloaders\n",
    "    dataloaders = get_dataloaders(datasets, batch_size=config.batch_size)\n",
    "\n",
    "    # Define model\n",
    "#     model = torchvision.models.resnet50()\n",
    "#     model = EfficientNet.from_name('efficientnet-b0')\n",
    "    model = torchvision.models.resnet50(pretrained=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 2) \n",
    "    model = model.to(device)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Train the model\n",
    "#     train_model(dataloaders, model, criterion, optimizer, num_epochs=15, file_name=ds)\n",
    "#     train_model_mixup(dataloaders, model, criterion, optimizer, num_epochs=15, file_name=ds, mixup_epochs=10)\n",
    "    eval_dict[ds]= train_model_mixup_el_stop(\n",
    "        dataloaders,\n",
    "        model, \n",
    "        criterion,\n",
    "        optimizer,\n",
    "        num_epochs=config.num_epochs,\n",
    "        file_name=ds, \n",
    "        mixup_epochs=config.mixup_epochs,\n",
    "        patience=config.patience\n",
    "    )\n",
    "\n",
    "del df\n",
    "del dataloaders\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ea2a53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a91d7f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc_ave = sum(eval_dict.values()) / len(eval_dict)\n",
    "acc_ave = round(acc_ave, 4)\n",
    "acc_ave = str(acc_ave)\n",
    "acc_ave = acc_ave.replace('.', '_')\n",
    "\n",
    "print(acc_ave)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddede80",
   "metadata": {},
   "source": [
    "## 予測フェーズ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acdc761",
   "metadata": {},
   "source": [
    "### 関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b34d36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = os.listdir(root_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.image_files[idx])\n",
    "        image = cv2.imread(img_path)  # Use OpenCV to read the image\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image)\n",
    "            image = transformed[\"image\"]\n",
    "        return image, self.image_files[idx] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebb0f43",
   "metadata": {},
   "source": [
    "### 実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebea41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_dict = get_transforms()\n",
    "\n",
    "test_data = TestDataset(root_dir='../data/evaluation/', transform=transforms_dict['valid'])\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "# モデルのパスをリストにします\n",
    "model_paths = [\n",
    "    f'../models/{formatted_datetime}_train_1.pth',\n",
    "    f'../models/{formatted_datetime}_train_2.pth',\n",
    "    f'../models/{formatted_datetime}_train_3.pth',\n",
    "    f'../models/{formatted_datetime}_train_4.pth',\n",
    "] \n",
    "\n",
    "# 空のリストを作成して各モデルの予測を格納します\n",
    "all_predictions = []\n",
    "\n",
    "for model_path in model_paths:\n",
    "    print('■実行中:', model_path)\n",
    "    \n",
    "    # モデルのインスタンスを作成します（ここではResNet34を使用）\n",
    "    model = torchvision.models.resnet50()\n",
    "    model.fc = nn.Linear(model.fc.in_features, 2) \n",
    "\n",
    "    # 状態辞書をロードします\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    # モデルをGPUに移動します\n",
    "    model = model.to(device)\n",
    "\n",
    "    # モデルを評価モードに設定します\n",
    "    model.eval()\n",
    "\n",
    "    # このモデルの予測を格納するリストを作成します\n",
    "    model_predictions = []\n",
    "\n",
    "    # データローダーからバッチを取得して予測を行います\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader):\n",
    "            images, _ = data\n",
    "            images = images.to(device)\n",
    "            \n",
    "            logits = model(images)\n",
    "            probabilities = F.softmax(logits, dim=1)  # apply softmax to convert logits to probabilities\n",
    "            model_predictions.extend(probabilities.tolist())  # convert PyTorch tensor to Python list\n",
    "\n",
    "    # すべてのモデルの予測を格納するリストにこのモデルの予測を追加します\n",
    "    all_predictions.append(model_predictions)\n",
    "\n",
    "# 全モデルの予測を平均します\n",
    "final_predictions = np.mean(all_predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7517aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit用に整形\n",
    "# Create a DataFrame with the image names and the probabilities\n",
    "df_submission = pd.DataFrame({\n",
    "    'image_name': [f'test_{i}.png' for i in range(len(final_predictions))],\n",
    "    'probability': [probs[1] for probs in final_predictions]\n",
    "})\n",
    "\n",
    "# Write the DataFrame to a csv file\n",
    "# df_submission.to_csv(f'../data/submit/submission_{formatted_datetime}_acc{acc_ave}.csv', index=False,header=False)\n",
    "df_submission.to_csv(f'../data/submit/submission_{formatted_datetime}.csv', index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be7a868",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.probability.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcb6f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.probability.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac8955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.probability.max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
